# 議事録：ローカルAgent Teamsシステム構築プロジェクト

**日時**: 2026年2月18日  
**参加者**: ユーザー（プロジェクトオーナー）、Claude（技術アドバイザー）  
**目的**: Claude Code Agent Teamsの仕組みをローカルLLMで再現し、独自のDual-Teamエージェントシステムを設計・実装する  

---

## 経緯の要約

本プロジェクトは、「Claude Code Agent Teamsのようなマルチエージェントの仕組みを、Ollamaのローカルモデルで自分の手元で動かしたい」という問いから始まり、5段階の議論を経て、最終的にプランニングチーム（4ペルソナ会議）と実行チーム（Coder/Tester/Reviewer/Replanner）による独自のDual-Teamシステムの設計・実装に到達した。

---

## 第1フェーズ：実現可能性の調査

### 問い
「Claude Code Agent TeamsをOllamaのローカルLLMで実現できますか？」

### 調査結果
- Agent Teamsの技術的基盤（JSONファイルベースのタスクリスト・Inboxメッセージング・独立プロセスとしてのエージェント）を調査
- OllamaがAnthropic互換APIを提供しており、Claude Codeのモデル層をローカルモデルに差し替え可能であることを確認
- ただし、Agent Teamsの高度なオーケストレーション機能はClaude級モデルの推論力を前提としており、ローカルLLMでは推論能力・速度・コンテキスト容量の面で実用的な成果を得るのは困難と評価

### 決定事項
- Agent Teamsの「仕組み」を理解し、それをフレームワーク（CrewAIなど）で再現する方針を採用
- Claude Code Agent Teamsを直接使うのではなく、同等のアーキテクチャパターンを自作する方向へ

---

## 第2フェーズ：Agent Teamsのアーキテクチャ分析と再現方針

### 問い
「Agent Teamsの仕組みを理解し、自分で動かせるものを作り、実際にエージェントチームに任せることが適したタスクを業務設計して実行したい」

### Agent Teamsのアーキテクチャ分析結果

Agent Teamsは以下5つの構成要素で成り立つことを特定した：

1. **リードエージェント** — タスク分解・調整・結果統合を担う中央ノード
2. **チームメイト** — 各自独立したコンテキストウィンドウで作業する専門エージェント
3. **タスクシステム** — `~/.claude/tasks/{team-name}/` にJSONファイルとして格納。ステータス遷移と依存関係管理
4. **メッセージングシステム** — `~/.claude/teams/{team-name}/inboxes/` にJSONファイル。アトミック書き込み（tempfile + os.replace）
5. **チーム設定** — `config.json` にメンバー一覧・エージェントID・タイプを記録

サブエージェントとの決定的な違いは「エージェント間の直接通信」であることを確認。サブエージェントは親への報告のみだが、Agent Teamsはメッシュ型の通信が可能。

### フレームワーク選定

| 候補 | 評価 | 判定 |
|------|------|------|
| CrewAI | ロールベース設計、Ollama完全対応、学習曲線が低い | **採用（推奨）** |
| LangGraph | グラフベースの状態管理、複雑なフロー向き | 代替候補 |
| AutoGen | 会話ベースのマルチエージェント | 参考 |
| claude-code-teams-mcp | Agent Teamsプロトコルの再実装 | 最も忠実だが要MCP環境 |

### 決定事項
- CrewAI + Ollamaを主軸とする
- Agent Teamsに適したタスクパターンを4つ特定（マルチ視点レビュー、競合仮説デバッグ、クロスレイヤー機能開発、リサーチ並列処理）

### 成果物
- → 別添資料A：汎用的なAgent Teams解説とCrewAI実装ガイド (`local-agent-teams-guide.md`)

---

## 第3フェーズ：ハードウェア環境の特定と最適化

### ユーザーから提示された環境情報

| マシン | 用途 | スペック |
|--------|------|---------|
| M4 MacBook Pro 128GB | 開発・テスト（持ち運び） | Apple Silicon, 128GB統合メモリ |
| ASUS Ascent GX10 | 本番実行（常時稼働） | NVIDIA GB10 Blackwell GPU, 128GB LPDDR5x統合メモリ, 1000 TOPS, DGX OS |
| 主使用モデル | gpt-oss:20b | OpenAI製, 21Bパラメータ (3.6B active), MoE, MXFP4量子化 |

### 環境評価で判明した重要ポイント

- **gpt-oss:20bはAgent Teams用途に非常に適している**: ネイティブfunction calling対応、chain-of-thought推論（reasoning effort制御可能）、MoEで活性パラメータ3.6Bのため推論が速い、メモリ使用量16GB以下
- **GX10のBlackwell GPUはMXFP4をハードウェアネイティブ処理**: gpt-oss:20bのMXFP4量子化との相性が極めて良い
- **128GBメモリで複数エージェント並列実行が余裕**: `OLLAMA_NUM_PARALLEL=4` で4エージェント同時リクエストが可能

### 新たな発想：2台のリモート連携

Claudeから「MacBookで開発してGX10のOllamaをリモートで使う」アーキテクチャを提案。ユーザーは「2つのマシンをリモートで同時に使う発想はなかった」と反応。

連携方法：
```
MacBook → OLLAMA_HOST=http://gx10.local:11434 → GX10上のOllama
```

### 決定事項
- MacBook = 開発・テスト・一緒に考える用
- GX10 = 本番実行・作業しておいてもらう用
- 開発時はMac上の軽量モデルで動作確認

### 成果物
- → 別添資料B：環境最適化ガイド (`agent-team-your-env.md`)
- → 別添資料C：CrewAI版実装コード (`agent_team_crewai.py`)

---

## 第4フェーズ：Dual-Teamアーキテクチャの構想

### ユーザーの構想（原文要約）

ユーザーから独自のDual-Teamシステム構想が提示された。以下がその要点：

**プランニングチーム（Phase 1）:**
- 4つのペルソナを持つエージェントが「会議」する
  1. プラグマティックな現実主義者
  2. ビジョナリーな理想主義者
  3. 極度のめんどくさがりの効率主義者
  4. リスク感度が抜群に高い管理主義者
- 互いに批判的に議論し、ユーザーに質問を投げる
- 3回以上のラウンドを繰り返し、視点を研ぎ澄ます
- 合議の上、テスト設計を含むプランを提出する

**実行チーム（Phase 2）:**
- プラン承認後に作業者チームに交代
- Coder: プランに従ってコードを書く。差異があれば修正
- Tester: テスト実行、エラー内容を詳述
- Reviewer: コードとエラーをレビュー、プラン実現性を評価
- Replanner: 評価に基づき修正プランを作成
- サイクルを繰り返し、完成したら人間＋プランニングチームにレビュー依頼

**追加要望:**
- スマートフォンからも会話できるとよい

### Claudeの評価

ユーザーの構想について以下の3点を特に高く評価した：

1. **4人のペルソナの緊張関係が設計品質を上げる**: 「ビジョナリー vs めんどくさがり」の対立軸がプロの設計チームの議論を再現。管理主義者が「壊れたら？」と問い、現実主義者が技術的な線を引く
2. **プランニングと実行の分離が正しい**: 同じエージェントに思考と実行を両方させるとコンテキストが汚れる。チーム分離で各自の役割に集中できる
3. **リプランナーが鍵**: テスト失敗時に単純なコード修正ループに陥ることを防ぎ、「アプローチ自体の変更」という判断ができる

### ユーザーへの確認事項と回答

| 質問 | 回答 | 設計への影響 |
|------|------|------------|
| 会議でのやりとり形式は？ | どれでもOK。通信文字数がボトルネックにならないのがいい | Web UI（FastAPI + Swagger）を採用。スマホブラウザから参加可能 |
| 実行チームの自律的なファイル操作を許可するか？ | Git branchで隔離すれば自律OK | `git checkout -b agent/plan-xxx` で隔離。全操作を自動commit |
| 主な開発言語は？ | その他（固定しない） | 言語非依存のファイル書き込みフォーマットを採用（`--- FILE: path ---`形式） |

### 決定事項
- Dual-Teamアーキテクチャを正式採用
- Phase 1（プランニング） → 承認 → Phase 2（実行） → レビュー → 再議論のフルサイクルを設計
- スマホ参加はFastAPI + Swagger UIで実現可能

### 成果物
- → 別添資料D：Dual-Teamアーキテクチャ設計書 (`dual-team-architecture.md`)

---

## 第5フェーズ：Mac簡易版プロトタイプの実装

### 問い
「まずは妄想が実現するとどれだけ素晴らしいかテストしたい。全部Mac上で動く簡易版を軽いモデルで作りたい。各LLMの施工過程や議論の内容が常に見えるといいな」

### 設計判断

| 判断項目 | 決定 | 理由 |
|---------|------|------|
| 外部パッケージ依存 | ゼロ（標準ライブラリのみ） | MacBookに持っていって `python3` だけで動くことを優先 |
| LLM呼び出し | `urllib` で Ollama `/api/chat` を直接叩く | CrewAI等のフレームワーク依存を排除 |
| 可視性 | トークンストリーミング + カラー出力 | LLMが1トークンずつ生成する様子をリアルタイム表示 |
| デフォルトモデル | `qwen2.5-coder:7b` | 軽量テスト用。環境変数で gpt-oss:20b に切替可能 |
| ファイル構成 | 1ファイル完結（800行） | プロトタイプとしての手軽さを優先 |

### ペルソナの実装方針

単なる機能ロール（「セキュリティ担当」等）ではなく、以下の要素をすべてプロンプトに埋め込んだ：

- **思考の癖**: 「既存ライブラリで解決できないか」「めんどくさい」「壊れたらどうなる」
- **口調**: 現実主義者は端的、効率主義者はだるそう、管理主義者は心配性
- **他メンバーへの態度**: 誰と同盟し、誰に突っ込むかを明示的に定義
- **reasoning effort**: リードは "high"、ワーカーは "medium" / "low" で分離

### 可視化の実装

```
各エージェントの表示:
  🔧 現実主義者        — 青
  🌟 理想主義者        — マゼンタ
  😴 効率主義者        — 黄
  🛡️ 管理主義者        — 赤
  🔨 Coder            — 緑
  🧪 Tester           — シアン
  📋 Reviewer          — 黄
  📝 Replanner         — マゼンタ
```

Ollamaの `stream: true` オプションにより、LLMが1トークン生成するたびに画面に表示される。エージェントが「何を考えているか」がリアルタイムで見える。

### 成果物
- → 別添資料E：Mac簡易版プロトタイプコード (`dual_team.py`)

---

## 意思決定の変遷マップ

```
Q: ローカルでAgent Teamsできる？
  │
  ├─ 調査 → 仕組みは再現可能だがモデル性能が課題
  │
  ▼
Q: じゃあ仕組みを理解して自作したい
  │
  ├─ アーキテクチャ分析 → 5構成要素を特定
  ├─ フレームワーク選定 → CrewAI + Ollama
  ├─ 適したタスクパターン → 4パターン特定
  │
  ▼
環境情報: M4 Mac 128GB + ASUS GX10 + gpt-oss:20b
  │
  ├─ 環境評価 → 非常に恵まれている
  ├─ 新発想 → 2台リモート連携
  ├─ 最適化 → gpt-oss:20b × Blackwell GPU が好相性
  │
  ▼
ユーザーの構想: Dual-Teamシステム
  │
  ├─ プランニングチーム（4ペルソナ会議）
  ├─ 実行チーム（Coder/Tester/Reviewer/Replanner）
  ├─ 要件確認 → Git隔離OK / 言語非依存 / スマホ参加
  │
  ▼
最終実装: Mac簡易版プロトタイプ
  │
  ├─ 1ファイル800行 / ゼロ依存
  ├─ トークンストリーミングで全過程可視化
  └─ ollama pull + python3 で即実行
```

---

## 別添資料一覧

| 資料 | ファイル名 | 内容 |
|------|-----------|------|
| A | `appendix_a_agent_teams_guide.md` | Agent Teamsのアーキテクチャ解説と汎用的なCrewAI実装ガイド（第2フェーズ成果物） |
| B | `appendix_b_env_optimization.md` | GX10 + gpt-oss:20b 環境最適化ガイド（第3フェーズ成果物） |
| C | `appendix_c_crewai_impl.md` | CrewAI版Agent Teams実装コード（第3フェーズ成果物） |
| D | `appendix_d_architecture.md` | Dual-Teamアーキテクチャ設計書：ペルソナ定義・会議プロトコル・実行チーム・Web API（第4フェーズ成果物） |
| E | `appendix_e_prototype.md` | Mac簡易版プロトタイプ：ゼロ依存の完全実装コード（第5フェーズ成果物） |

---

## 次のアクション

1. MacBookで `ollama pull qwen2.5-coder:7b` + `python3 dual_team.py` を実行し、Dual-Teamシステムを体験する
2. 4ペルソナの議論品質を確認し、バックストーリー（プロンプト）を自分の好みに調整する
3. 満足したら `AGENT_MODEL=gpt-oss:20b` に切り替えて品質差を比較する
4. GX10でのリモート実行（`OLLAMA_HOST=http://gx10.local:11434`）を試す
5. 必要に応じて設計書（別添D）のWeb API部分を実装し、スマホからの参加を実現する
