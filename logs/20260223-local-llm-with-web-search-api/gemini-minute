# 議事録：ローカルLLM統合型 Multi-Tool RAGシステム アーキテクチャ策定

## 1. 開催概要

* **テーマ:** 外部検索APIと内部ドキュメントを組み合わせたLLMエージェントのアーキテクチャ設計
* **目的:** 要件の明確化および、情報の取得・統合・推論における最適なシステム構成の決定

## 2. 意思決定プロセス（議論の推移）

### フェーズ1：基本アプローチの方向付け

* **課題:** ローカルLLM単体では最新情報や知識が不足しており、ハルシネーションのリスクがある。
* **初期検討:** 外部の検索ツール（クラウドLLMのグラウンディング機能や検索API）を利用し、検索結果をコンテキストとしてローカルLLMに渡す構成を確認。

### フェーズ2：外部検索の高度化（並列化の採用）

* **検討事項:** 単一の検索エンジンへの依存は、情報の偏りや見落としを生む可能性がある。より広範な情報から精緻な情報を引き出すにはどうすべきか。
* **決定事項:** 複数のWeb検索API（Tavily, Brave Search等）を並列で呼び出す「Multi-Tool RAG」アプローチを採用。情報の網羅性向上と事実のクロスチェックを可能にする方針とした。

### フェーズ3：内部ドキュメント（固有文脈）の統合

* **検討事項:** Web上の一般情報だけでなく、固有の設計資料やルール（Markdownファイル等）をベースにした回答が求められる。
* **決定事項:** 外部APIからの「Webスニペット」と、ローカルベクトルDBからの「内部Markdownチャンク」を同時に取得し、これらを組み合わせて新たな文脈を形成するハイブリッド検索アーキテクチャを採用。

### フェーズ4：推論・情報統合プロセスの完全ローカル化

* **検討事項:** 収集した情報の「統合・精製」をクラウドLLMに任せるか、ローカルLLMで行うか。
* **決定事項:** 検索フェーズのみを外部APIに依存し、情報の「統合（中間レポート作成）」「競合解決」「最終生成」のすべての推論処理を、ローカルLLM（`gpt-oss-20b`）で実装する方針で確定。

## 3. 最終決定事項（システム設計の要件）

1. **基本構成:** 外部データフェッチ ＋ 内部ローカルRAG ＋ 2段階ローカルLLM推論
2. **中核モデル:** `gpt-oss-20b`（ローカル環境）
3. **データ取得:** 外部Web検索API（並列処理）およびローカルのベクトルデータベース
4. **競合解決ルール:** 外部Web情報と内部Markdown情報間で矛盾が生じた場合、常に内部情報を正（グラウンドトゥルース）として優先する。
5. **成果物:** 上記の意思決定に基づき、Markdown形式の「システム設計仕様書」を作成し、出力完了。
